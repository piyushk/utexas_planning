////////////////////////////////////////////////////////////////////
//
// Light World MDP
//
// Author: Piyush Khandelwal (piyushk [at] gmail.com)
//
// This domain is a modified version of the Light World domain presented in:
// Konidaris, George, and Andrew G. Barto. "Building Portable Options: Skill Transfer in Reinforcement Learning." IJCAI.
// Vol. 7. 2007.
//
// In a grid, a robot (R) must get to a goal (G). To get the goal reward, the agent must first unlock a lock in the room
// and then reach the goal. The robot first needs to find a key to the lock, and then unlock the lock. Once the robot
// picks up the key, it has X attempts to use it before the key becomes unusable.  In addition, using the key
// successfully is not deterministic.  Consequently, it is in the robot's interest to ensure that it gets to the locks
// location before attempting to use the key.
//
////////////////////////////////////////////////////////////////////

domain light_world_mdp {
	requirements = {
		reward-deterministic,
    intermediate-nodes
	};

	types {
		xpos : object;
		ypos : object;
	};

  types {
    movement_dir : { @north , @south , @east, @west, @noop }; // An enumerated type
   };

	pvariables {

		NORTH(ypos, ypos) : {non-fluent, bool, default = false};
		SOUTH(ypos, ypos) : {non-fluent, bool, default = false};
		EAST(xpos, xpos)  : {non-fluent, bool, default = false};
		WEST(xpos, xpos)  : {non-fluent, bool, default = false};

		MIN-XPOS(xpos) : {non-fluent, bool, default = false};
		MAX-XPOS(xpos) : {non-fluent, bool, default = false};
		MIN-YPOS(ypos) : {non-fluent, bool, default = false};
		MAX-YPOS(ypos) : {non-fluent, bool, default = false};

		GOAL(xpos,ypos) : {non-fluent, bool, default = false};
		KEY(xpos,ypos) : {non-fluent, bool, default = false};
		LOCK(xpos,ypos) : {non-fluent, bool, default = false};

    MOVEMENT_NONDETERMINISM : {non-fluent, real, default = 0.1};

		// Fluents
		robot-at(xpos, ypos) : {state-fluent, bool, default = false};
    unlock-attempts-left : {state-fluent, int, default = 5};
		key-picked-up : {state-fluent, bool, default = false};
		goal-locked : {state-fluent, bool, default = true};

    // Movement dynamics via interm fluents.
    num-valid-dirs : {interm-fluent, int, level = 1};
    movement-dir : {interm-fluent, movement_dir, default = @noop, level = 2};

		// Actions
		move-north : {action-fluent, bool, default = false};
		move-south : {action-fluent, bool, default = false};
		move-east  : {action-fluent, bool, default = false};
		move-west  : {action-fluent, bool, default = false};
		pickup  : {action-fluent, bool, default = false};
		unlock  : {action-fluent, bool, default = false};
	};

	cpfs {

    num-valid-dirs =
      ((exists_{?x : xpos, ?y : ypos, ?y2 : ypos} [NORTH(?y,?y2) ^ robot-at(?x,?y)]) +
       (exists_{?x : xpos, ?y : ypos, ?y2 : ypos} [SOUTH(?y,?y2) ^ robot-at(?x,?y)]) +
       (exists_{?x : xpos, ?y : ypos, ?x2 : xpos} [EAST(?x,?x2) ^ robot-at(?x,?y)]) +
       (exists_{?x : xpos, ?y : ypos, ?x2 : xpos} [WEST(?x,?x2) ^ robot-at(?x,?y)]));

    movement-dir =
      if (move-north | move-south | move-east | move-west)
      then
        Discrete(movement_dir,
                 @north: if (move-north)
                         then
                           (1.0 - MOVEMENT_NONDETERMINISM + (MOVEMENT_NONDETERMINISM / num-valid-dirs))
                         else
                           (MOVEMENT_NONDETERMINISM / num-valid-dirs),
                 @south: if (move-south)
                         then
                           (1.0 - MOVEMENT_NONDETERMINISM + (MOVEMENT_NONDETERMINISM / num-valid-dirs))
                         else
                           (MOVEMENT_NONDETERMINISM / num-valid-dirs),
                 @east:  if (move-east)
                         then
                           (1.0 - MOVEMENT_NONDETERMINISM + (MOVEMENT_NONDETERMINISM / num-valid-dirs))
                         else
                           (MOVEMENT_NONDETERMINISM / num-valid-dirs),
                 @west:  if (move-west)
                         then
                           (1.0 - MOVEMENT_NONDETERMINISM + (MOVEMENT_NONDETERMINISM / num-valid-dirs))
                         else
                           (MOVEMENT_NONDETERMINISM / num-valid-dirs))
      else
        KronDelta(@noop);

		robot-at'(?x,?y) =

      // Check if the robot moved, and was at this location last.
      if ((move-north | move-south | move-east | move-west) ^ robot-at(?x, ?y))
        then KronDelta(false)
      else if (((movement_dir == @north) ^ exists_{?y2 : ypos} [NORTH(?y,?y2) ^ robot-at(?x,?y)]) |
               ((movement_dir == @south) ^ exists_{?y2 : ypos} [SOUTH(?y,?y2) ^ robot-at(?x,?y)]) |
               ((movement_dir == @east) ^ exists_{?x2 : xpos} [EAST(?x,?x2) ^ robot-at(?x,?y)]) |
               ((movement_dir == @west) ^ exists_{?x2 : xpos} [WEST(?x,?x2) ^ robot-at(?x,?y)]))
			then
				KronDelta(true)
			else
				KronDelta(robot-at(?x,?y));

     unlock-attempts-left' =
       if (unlock ^ unlock-attempts-left > 0)
       then
         unlock-attempts-left - 1
       else
         unlock-attempts-left;

     key-picked-up' =
       if (pickup ^ exists_{?x : xpos, ?y : ypos} [KEY(?x, ?y) ^ robot-at(?x, ?y)])
       then
         KronDelta(true)
       else
         KronDelta(key-picked-up);

     goal-locked' =
       if (unlock ^ (unlock-attempts-left > 0) ^ exists_{?x : xpos, ?y : ypos} [LOCK(?x, ?y) ^ robot-at(?x, ?y)])
       then
         KronDelta(false)
       else
         KronDelta(goal-locked);

	};

	// 0 reward for reaching goal, -1 in all other cases
	reward =
    if (~goal-locked ^ exists_{?x : xpos, ?y : ypos} [GOAL(?x, ?y) ^ robot-at(?x, ?y)]) then 0.0 else -1.0;

  state-action-constraints {
    // Invalid moves. Equivalent to noop.
		forall_{?x : xpos, ?y : ypos} MIN-XPOS(?x) ^ robot-at(?x, ?y) => ~move-west;
		forall_{?x : xpos, ?y : ypos} MAX-XPOS(?x) ^ robot-at(?x, ?y) => ~move-east;
		forall_{?x : xpos, ?y : ypos} MIN-YPOS(?y) ^ robot-at(?x, ?y) => ~move-south;
		forall_{?x : xpos, ?y : ypos} MAX-YPOS(?y) ^ robot-at(?x, ?y) => ~move-north;

		// Remove the noop action if not at the goal.
    (goal-locked | ~(exists_{?x : xpos, ?y : ypos} [GOAL(?x, ?y) ^ robot-at(?x, ?y)])) =>
      [(move-north + move-south + move-east + move-west + pickup + unlock) == 1];

    // Remove the pickup action if the key has been picked up.
    key-picked-up => ~pickup;

    // Remove the unlock action if the lock has been unlocked.
    ~goal-locked => ~unlock;

    // Remove the movement action if at the goal.
    (~goal-locked ^ exists_{?x : xpos, ?y : ypos} [GOAL(?x, ?y) ^ robot-at(?x, ?y)]) => ~move-west;
    (~goal-locked ^ exists_{?x : xpos, ?y : ypos} [GOAL(?x, ?y) ^ robot-at(?x, ?y)]) => ~move-east;
    (~goal-locked ^ exists_{?x : xpos, ?y : ypos} [GOAL(?x, ?y) ^ robot-at(?x, ?y)]) => ~move-south;
    (~goal-locked ^ exists_{?x : xpos, ?y : ypos} [GOAL(?x, ?y) ^ robot-at(?x, ?y)]) => ~move-north;
  };

//	state-action-constraints {
//
//		// Robot at exactly one position
//		[sum_{?x : xpos, ?y : ypos} robot-at(?x,?y)] <= 1;
//
//		// EAST, WEST, NORTH, SOUTH defined properly (unique and symmetric)
//		forall_{?x1 : xpos} [(sum_{?x2 : xpos} WEST(?x1,?x2)) <= 1];
//		forall_{?x1 : xpos} [(sum_{?x2 : xpos} EAST(?x1,?x2)) <= 1];
//		forall_{?y1 : ypos} [(sum_{?y2 : ypos} NORTH(?y1,?y2)) <= 1];
//		forall_{?y1 : ypos} [(sum_{?y2 : ypos} SOUTH(?y1,?y2)) <= 1];
//		forall_{?x1 : xpos, ?x2 : xpos} [ EAST(?x1,?x2) <=> WEST(?x2,?x1) ];
//		forall_{?y1 : ypos, ?y2 : ypos} [ SOUTH(?y1,?y2) <=> NORTH(?y2,?y1) ];
//
//		// Definition verification
//		[ sum_{?x : xpos} MIN-XPOS(?x) ] == 1;
//		[ sum_{?x : xpos} MAX-XPOS(?x) ] == 1;
//		[ sum_{?y : ypos} MIN-YPOS(?y) ] == 1;
//		[ sum_{?y : ypos} MAX-YPOS(?y) ] == 1;
//		[ sum_{?x : xpos, ?y : ypos} GOAL(?x,?y) ] == 1;
//
//	};

}
